{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Generating quality driving data with Cosmos\n",
        "\n",
        "We provide a short demo using Cosmos-Predict to generate a short driving clip, and Cosmos-Reason to determine if the video is realistic enough for training.\n",
        "\n",
        "The video is indeed scored as real (=0). If we decide Cosmos-Reason is a good enough critic, we can increase this video's generation to create large datasets for training and set up evaluation benchmarkings, noting their source origin.\n",
        "\n",
        "We can also argue this video is not of good enough quality. In reviewing the video, we see artifacts propagated from present to future frames, and a large amount of shakiness to the video. We could address the shakiness of the video by using different prompts, fine-tuning a Cosmos-Predict for  a single + fixed camera position, or review the datasets used to train this network."
      ],
      "metadata": {
        "id": "4UGaacGY8LN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cosmos_guardrail\n",
        "!pip install peft==0.17.0\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install ffmpeg libavformat-dev libavcodec-dev libavutil-dev\n",
        "#!pip install pyav\n",
        "!pip install torchvision\n",
        "!pip install av\n",
        "!pip install decord"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "x4H90rBJ0dUl",
        "outputId": "c870e6d4-c561-4540-d9ea-e88987a7030b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connecting to security.\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "libavcodec-dev is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "libavformat-dev is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "libavutil-dev is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 72 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bMnYbZlLrzgd"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "token = userdata.get('HF_TOKEn')\n",
        "login(token=token)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Cosmos-Predict-2B"
      ],
      "metadata": {
        "id": "Ok4fjKXc1Gk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import Cosmos2VideoToWorldPipeline\n",
        "from diffusers.utils import export_to_video, load_image\n",
        "import os\n",
        "\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
        "model_id = \"nvidia/Cosmos-Predict2-2B-Video2World\"\n",
        "pipe = Cosmos2VideoToWorldPipeline.from_pretrained(model_id, torch_dtype=torch.bfloat16)\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"A drive on the highway at night in Seoul, going back home into the city, and driving very well obeying all traffic laws.\"\n",
        "image = load_image(\n",
        "    \"/content/night_highway_drive.jpg\"\n",
        ")\n",
        "\n",
        "video = pipe(\n",
        "    image=image, prompt=prompt, generator=torch.Generator().manual_seed(1)\n",
        ").frames[0]\n",
        "export_to_video(video, \"night_highway_drive.mp4\", fps=16)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393,
          "referenced_widgets": [
            "347b16258b0f40ae8a97c20a32e51021",
            "9f795187dcce45b49a254eaf37a820a6",
            "05b5094da2a44df6aecb6a15ee402181",
            "814a963e5dea44b1924c499e0e5ad41e",
            "88af87da4826432eac6907b01bba1385",
            "52b43295157243d3a91aa8134633281e",
            "02faa830233f435ea116f38c792e3c54",
            "1bb5adffdd454834be48e5f9b3ccad45",
            "abdf93a2788c40309d56bc7ef6ae89cd",
            "03b37130047a4563b2157afe1e53762c",
            "1e1ac65ffee94105a3cbe3708dff1230",
            "a27c9c5e7281420dafa2fe23ca4047e4",
            "314c20ecc24b4cce9f23358229e4853a",
            "5d4e648f4ff64acb801469350bc120da",
            "7e73a3b0cd0a49c7bf3e08b54ace8c81",
            "1cf1540e6def44f192f983c5ffd5c560",
            "438ea7637e3145a8aba946fa18e794b7",
            "48ab601daf314454ac6a0586b4a475dc",
            "f4a9dc0d6f484b528e02c560ced381f1",
            "4b0d24066fe5439db3e33ccec0f2e6f6",
            "32a5fb7d954347c0840c1f16f43bd77d",
            "a359cccf59f940ea8114d1cdb48d2ee5",
            "1ec5a643ccbc497d992142c064294e83",
            "e774640c21ee4bd0aabb8d8c6941734c",
            "dfe7ca9345e94d4b9f046a2db087cbf9",
            "ee549570270f49ffb57cc2a1df821a9f",
            "731fd76dfb474c1ab879c4db037d2d66",
            "be26468d23aa4ac4acd2f24d4aff8e2e",
            "d9fb6b803ff9480796437309a07094c8",
            "156b7a8e78ac4edb8b1207367f119178",
            "8fa8cf3c04824aa4801d7eb98fe4ae40",
            "166806858ac74fa6b59797cc24d1ed57",
            "e3ce21503c7d4f1d98246678cfa39820",
            "3900814e9eb948fcba86e43ea9c7cca3",
            "031d4e1e60d3455ab196dbe2eccfa598",
            "b2b64aea0a6d4de7beef09f5efb81118",
            "becb03d2ed004d63818cde3bd56c770f",
            "932be0e9ee904d3da22d4bc021e622e0",
            "55ce81a5142545f8a1b227820c5c915a",
            "83aa25530f54421d87dbfd9f39f5a2ee",
            "c352536157354a99bc52c3a0dc65b9ff",
            "3872c19075e542e688352ccdeb6d1328",
            "122b90d6ce4e40838c87d3fb63f998bb",
            "c3b3422f3f734a1e9bf4af8f8a76293a",
            "865c78e2a757484889452703cd8d2a46",
            "ecc7e17568ef4d3180c9efb77f7f3d6a",
            "f47e4d443f7045cab8205465888468c5",
            "dfb81bbb27cc4123814c1dd90ff2cce1",
            "e8a179fc6e174b0d9e2d16eaad1859b5",
            "6bf07b4bb0734a958d86af4adcab81b4",
            "132371531cf6438e98fa2b4286c74ea1",
            "854ef5a6863b45e5a40f282e7f99e72d",
            "6195abbe57b44013a536e97b498d4d58",
            "5be176b2a445489aa71ffdbebaa48b02",
            "ac87b611b88c451db7b02a0a8fffd5c7",
            "6dc0131bcfec41d6b742c429ef5cc837",
            "00beaf84d1b34970bcbc84fa79ae100e",
            "188b674bc7d043fb96d25bede8729485",
            "5ef0647d17534be5884e7f82eb444886",
            "ab98e45b3e34427c88969e2b3c924f0c",
            "22642f4916b0400a9ab4dfc51a8ade10",
            "6af3d56044cb43379a47c697213e9e71",
            "3570394a3e5542de805549ba86392e2e",
            "cf9bfcd2ece44afc86502d2c6bc1af48",
            "b04be43d494748fe8213dd466cfdc6f2",
            "a1c0ce24c28a4a10b07387429bbeb8d2",
            "ff1244c199f24e6e814b04eae035de60",
            "e9f75d9255624eafa8db8ebc61313cd8",
            "8748a1be961d49b88e869388dc0a938d",
            "d206738d94d84bb4b5ec57ff7e0cf197",
            "4dcac6b808ad40f9adbab2245b4aaefb",
            "4f4360f2ee7c499aa635511124144da1",
            "40ad003c5f544d9982aa4a484001d2f0",
            "ed865e18d9bc4a54aef4725c2be4c02d",
            "e17b8388e0e94eeea0e0ad21b86ef211",
            "17f6213596144659a879ea8bf68188ba",
            "95818c473cc740b6bdec7e9a6091aabf",
            "091fa2d540464ea9a7a542d7dc33351c",
            "372d143e25b34a44bf7c0927f90340ca",
            "cd906185978946dabcc7e7d8004c47fd",
            "7725348969c547d9838c841d19dc885b",
            "b24c20a739d74f71954a7edafbf33c56",
            "c509f3445e994bed878f2e45a01997dc",
            "f65f43a0685f4583a3ff55cb2b493c2c",
            "2ec0cd2b46e549fd888ddba4e8548c09",
            "3b50b44b56b64134addd657d466d1a43",
            "6a0bba0c5d3b4374a613b752b9121cba",
            "0b33d375f7e743138fc39b0de91de113",
            "c7dc2c47eff845caa9483accb57c5715",
            "68b61617c7f24db89423dabd7b7fbd60",
            "8d8fa091f7af4159b29317e008871d05",
            "add1272cad9d44cb86244a18c4108a5c",
            "d8902066d7644538baabcf886a3da978",
            "641faf233ff24022842ed80074c4bbfb",
            "401ddbb8a30f4627ab6154c20c68b6a2",
            "ea443985916c468aa412be52f51a669d",
            "6e9ad47e0e704016bb245f0f9ad2a481",
            "b119c9a7348048a6be4d63fe8be36eb6",
            "1503de01fa204eb38daa0444a5366975",
            "c32faec9cee844cb9473e90e09cf7e63",
            "dadcbc3d91bf4cdf8f8efda094836a4e",
            "e6cfbb1050eb4c2bb4f6b1167775dbb1",
            "f4f82b15e9f34117999ae408d8dad684",
            "f05090fceabe4bc387c5a6b8b9b4ee4f",
            "69dff0d64e6147c587a4d444c98621a6",
            "e9c2e54351ab4803977330acb06807d4",
            "bc62796eaa544bb48f7a37237595b673",
            "99008bd2baea4b9681811b424ded00df",
            "fde3095085b549c7aca94657cb14c229",
            "09edf1dc44d44cc188c0400432a32f95"
          ]
        },
        "id": "i-j9PYkptXO0",
        "outputId": "5a9379ac-5a15-45cb-81e4-4e06d6e96f5a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "347b16258b0f40ae8a97c20a32e51021"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The config attributes {'final_sigmas_type': 'sigma_min', 'sigma_data': 1.0, 'sigma_max': 80.0, 'sigma_min': 0.002} were passed to FlowMatchEulerDiscreteScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a27c9c5e7281420dafa2fe23ca4047e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 146 files:   0%|          | 0/146 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ec5a643ccbc497d992142c064294e83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 146 files:   0%|          | 0/146 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3900814e9eb948fcba86e43ea9c7cca3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "865c78e2a757484889452703cd8d2a46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6dc0131bcfec41d6b742c429ef5cc837"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 146 files:   0%|          | 0/146 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff1244c199f24e6e814b04eae035de60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 146 files:   0%|          | 0/146 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "091fa2d540464ea9a7a542d7dc33351c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 146 files:   0%|          | 0/146 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7dc2c47eff845caa9483accb57c5715"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/35 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c32faec9cee844cb9473e90e09cf7e63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Cosmos-Reason1-7B\n",
        "We use Cosmos-Reason1-7B to determine if the video generated by Cosmos-Predict-2B is real (score = 0) or generated (score = 10). Cosmos-Reason-1B returns real, the generated video can be used for training."
      ],
      "metadata": {
        "id": "BPBCQ40ozeAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "jbxd3ymM4zGH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoProcessor\n",
        "from transformers import Qwen2_5_VLForConditionalGeneration\n",
        "\n",
        "critic_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
        "    \"nvidia/Cosmos-Reason1-7B\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        ").to(\"cuda\")\n",
        "critic_processor = AutoProcessor.from_pretrained(\"nvidia/Cosmos-Reason1-7B\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "0679370c92d14afda1060698e75c7eb2",
            "9b2d02ea4b4d4c468c8a3a230b5a8ff6",
            "c926b7b419f54b62a34408ed0ef8010d",
            "6401d6d4aef3475e885bdeea0c82ad31",
            "8f0dc00398704b2ebcce8277286223e8",
            "826695106f714a6c8306f1f087b4103b",
            "0a173e4988d94b85a234dadf6281150f",
            "db7fa2e914ec4f71a4c8580809a77d67",
            "72eba9feda944c849e096e4ff3ac211c",
            "57d41b7a0eec4b75a3004dda05b3a419",
            "9b3a32018b274984905ca1669885876e"
          ]
        },
        "id": "5x2a_i8Atdsi",
        "outputId": "c91b2838-5388-4efb-b712-852f054dfac0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0679370c92d14afda1060698e75c7eb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import decord\n",
        "import numpy as np\n",
        "\n",
        "video_path = \"/content/output.mp4\"\n",
        "video_frames = decord.VideoReader(video_path)\n",
        "total_frames = len(video_frames)\n",
        "\n",
        "# Reduce video frames so we don't run OOM.\n",
        "indices = np.linspace(0, total_frames - 1, num=5).astype(int)\n",
        "video_frames = video_frames.get_batch(list(range(total_frames))).asnumpy()\n",
        "processed_frames = []\n",
        "for frame in video_frames:\n",
        "    resized_frame = cv2.resize(frame, (224, 224))\n",
        "    processed_frames.append(resized_frame)\n",
        "video_frames = processed_frames\n",
        "\n",
        "critic_prompt = (\n",
        "    \"Rate this video between [1-10] as being AI generated (=10) or real (=0).\"\n",
        ")\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"video\", \"path\": video_path},\n",
        "            {\"type\": \"text\", \"text\": critic_prompt},\n",
        "        ],\n",
        "    },\n",
        "]\n",
        "text_prompt = critic_processor.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "inputs = critic_processor(\n",
        "    text=[text_prompt],\n",
        "    videos=[video_frames],\n",
        "    padding=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(\"cuda\", dtype=torch.bfloat16)"
      ],
      "metadata": {
        "id": "mbTuWTcD0BV3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "critique_output = critic_model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=128,\n",
        "    temperature=0.6,\n",
        "    do_sample=False\n",
        ")\n",
        "\n",
        "critique = critic_processor.decode(critique_output[0], skip_special_tokens=True)\n",
        "print(critique)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4iX0TSmcuRh4",
        "outputId": "71d1bcf5-8bad-4be4-91df-e50c0ef13988"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "system\n",
            "You are a helpful assistant.\n",
            "user\n",
            "Rate this video between [1-10] as being AI generated (=10) or real (=0).\n",
            "assistant\n",
            "0\n"
          ]
        }
      ]
    }
  ]
}
